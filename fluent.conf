<source>
	@type tcp
	tag monolog
	port "#{ENV['PORT']}"
	bind 0.0.0.0

	<parse>
		@type json
	</parse>
</source>

<filter monolog.v1>
	@type record_transformer
	enable_ruby

	<record>
		datetime "${
			require 'tzinfo';
			require 'date';
			TZInfo::Timezone
				.get(record['datetime']['timezone'])
				.local_to_utc(DateTime.parse(record['datetime']['date']))
				.strftime('%Y-%m-%dT%H:%M:%S.%N%Z')
		}"
	</record>
</filter>

<filter monolog.v2>
	@type record_transformer
	enable_ruby

	<record>
		extra ${!record.dig('extra').kind_of?(Hash) ? {} : record['extra']}
		context ${!record.dig('context').kind_of?(Hash) ? {} : record['context']}
	</record>
</filter>

<filter monolog.v2>
	@type record_transformer
	enable_ruby
	remove_keys $.extra.correlation_id, datetime

	<record>
		correlation_id ${record.dig('extra', 'correlation_id')}
		timestamp ${record['datetime']}
	</record>
</filter>

<filter monolog.v2>
	@type record_transformer
	enable_ruby

	<record>
		labels "${
		    record['extra'].merge(record['context'])
		        .filter{ |k,v| v.kind_of?(Numeric) or v.kind_of?(String) }
		        .map{ |k,v| { :key => k, :value => v.to_s.slice(0, ENV['LABEL_MAX_LENGTH'].to_i) } }
        }"
	</record>
</filter>

<match {monolog,monolog.v1}>
	@type rewrite_tag_filter
	<rule>
		key $.datetime
		pattern /\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}(.\d+)?(\-|\+)\d{1,2}:\d{1,2}/
		tag monolog.v2
	</rule>
	<rule>
		key $.datetime.date
		pattern /\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}(.\d+)?/
		tag monolog.v1
	</rule>
</match>

<match monolog.v2>
	@type bigquery_insert
	auth_method "#{ENV['AUTH_METHOD']}"
	private_key_path "#{ENV['PRIVATE_KEY_PATH']}"
	location "#{ENV['LOCATION']}"
	project "#{ENV['PROJECT']}"
	table "#{ENV['TABLE']}"
	dataset "#{ENV['DATASET']}"
	auto_create_table true
	schema_cache_expire 3600
	schema [
        { name: "timestamp", type: "TIMESTAMP" },
        { name: "correlation_id", type: "STRING" }
        { name: "level", type: "INT64" }
        { name: "level_name", type: "STRING" }
        { name: "channel", type: "STRING" }
        { name: "message", type: "STRING" }
        { name: "context", type: "STRING" }
        { name: "extra", type: "STRING" }
        { name: "labels", type: "RECORD", mode: "REPEATED", fields: [
            { name: "key", type: "STRING" },
            { name: "value", type: "STRING" }
        ] }
	]

	<buffer>
		@type file
		path /fluentd/data
		chunk_limit_size 128MB
		flush_interval 5s
		flush_mode interval
		flush_at_shutdown true
		overflow_action drop_oldest_chunk
	</buffer>
</match>
